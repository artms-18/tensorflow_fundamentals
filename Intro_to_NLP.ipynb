{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Intro_to_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyONCJJ4zJ4PkQQVga2wDzty",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/artms-18/tensorflow_fundamentals/blob/main/Intro_to_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2YYd-dzOCzO"
      },
      "source": [
        "# Introduction to NLP Fundamentals in Tensorflow\n",
        "\n",
        "NLP has the goal of deriving information out of natural language (could be sequences text or speech).\n",
        "\n",
        "Another common term for NLP problems is sequence to sequence problems (seq2seq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwL6eAuxOez1"
      },
      "source": [
        "## Check for GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NmbUEodOibH",
        "outputId": "ad4745f6-1a52-45c4-c633-caf66a702090"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-d1a39683-35f1-9f05-30d6-3746590b5730)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXRui5LaOmC1"
      },
      "source": [
        "## Get helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EKDbxTLOta0",
        "outputId": "b0280d7a-181a-4af7-c79c-fcfe7e03c1ad"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "\n",
        "# Import a series of helper function for the notebook\n",
        "\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-26 19:42:50--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-05-26 19:42:51 (94.3 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFOGPIupPDFD"
      },
      "source": [
        "## Get a text dataaset\n",
        "\n",
        "The dataset we're going to be using is Kaggle's introduction to NLP dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n07wcR_vPax1",
        "outputId": "f939239b-4029-4b97-aeca-360ae3cacf25"
      },
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
        "\n",
        "unzip_data(\"nlp_getting_started.zip\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-26 19:42:53--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.197.128, 74.125.20.128, 74.125.142.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.197.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2021-05-26 19:42:53 (103 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3ncZHW9NfqH"
      },
      "source": [
        "## Visualizing a text dataset\n",
        "\n",
        "To visualie our text samples, we first have to read them in, one way to do so would be to use Python: \n",
        "\n",
        "Another way to do this is to use pandas.\n",
        "\n",
        "(If text dataset is very large, cannot ise pandas (will tkaes of to much RAM).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "pMSX-pP6N4ZP",
        "outputId": "241913e2-6eaf-46f5-bd4d-930a4d4abcbf"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "train_df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6wEgvLPWOq38",
        "outputId": "825c16a6-cd0b-4644-9bac-1b554148ceca"
      },
      "source": [
        "train_df['text'][0]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "GMJJNtQQOzCx",
        "outputId": "9b4d90b8-fc0e-4828-9baf-be870e2ffac8"
      },
      "source": [
        "# Shuffle training dataframe\n",
        "\n",
        "train_df_shuffled = train_df.sample(frac = 1, random_state = 42)\n",
        "train_df_shuffled.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "2644  3796  ...      1\n",
              "2227  3185  ...      0\n",
              "5448  7769  ...      1\n",
              "132    191  ...      0\n",
              "6845  9810  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Wf5tQuYPPOI5",
        "outputId": "8b36c613-3fa2-4d1f-d378-324ca2b07dd1"
      },
      "source": [
        "# What does the test dataframe look like?\n",
        "\n",
        "test_df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85kR-NvnPYL5",
        "outputId": "acc1dfb3-7152-4c44-88dd-8b604fd20030"
      },
      "source": [
        "# How many examples of each class?\n",
        "train_df.target.value_counts()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNxPDFVsPjaE",
        "outputId": "da853afd-91e8-4512-8291-95024f2d6c26"
      },
      "source": [
        "# How many total samples?\n",
        "len(train_df), len(test_df)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 3263)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQBONc5XQB21",
        "outputId": "6145d409-d8f0-43e1-8188-4b42359db2ac"
      },
      "source": [
        "# Let's visualize some random training examples\n",
        "\n",
        "import random\n",
        "\n",
        "random_index = random.randint(0, len(train_df)-5) # create random indexes not higher than the total number of samples\n",
        "\n",
        "for row in train_df_shuffled[['text', 'target']][random_index: random_index + 5].itertuples():\n",
        "  _, text, target = row #gets rid of index\n",
        "  print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"---\\n\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target: 0 (not real disaster\n",
            "Text:\n",
            "@RaynbowAffair Editor In Chief @DiamondKesawn Releases Issue #7 http://t.co/7mzYcU2IHo of #RAmag. #Fashion #Models and #Mayhem\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster\n",
            "Text:\n",
            "Do you have an emergency drinking water plan? Download guide in English Spanish French Arabic or Vietnamese. http://t.co/S0ktilisKq\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster\n",
            "Text:\n",
            "Seen on Fahlo:#WCW All Hail the QueenåÊ?? http://t.co/oLpBmy9xw9 #MTVHottest Justin Bieber http://t.co/ON18cqGcoA\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster\n",
            "Text:\n",
            "Aftershock was the most terrifying best roller coaster I've ever been on. *DISCLAIMER* I've been on very few.\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "Severe thunderstorm warning remains for #Cochrane. @cityofcalgary has enacted municipal emergency plan after today's storm. #abstorm\n",
            "\n",
            "---\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YOA44HYRFO4"
      },
      "source": [
        "### Split data into training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLvaFplXVxYB"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T--31tdmV8-p"
      },
      "source": [
        "# Use train_test_split top split training data into training and validation sets\n",
        "\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled['text'].to_numpy(), train_df_shuffled['target'].to_numpy(),\n",
        "                                                                            test_size = 0.1, random_state = 42)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMmCJhagWgrX",
        "outputId": "b19174f1-4af9-412e-9b85-db875aa0afad"
      },
      "source": [
        "# Check the lengths\n",
        "\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1IAOaMvWn1h",
        "outputId": "a3bb917f-36c4-4bd0-d153-363594b351b9"
      },
      "source": [
        "# Check the first 10 samples\n",
        "\n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBPYFbfpWxka"
      },
      "source": [
        "## Converting text into numbers\n",
        "\n",
        "When dealing with a text problem, one of the first things you'll have to do before you can build a midek is to convert your text to numbers.\n",
        "\n",
        "There are a few ways to do this, namely:\n",
        "* Tokenization - direct mapping of  token( a toke could be a word or a character) to number\n",
        "* embedding - create a matrix of feature vectors for each token the size of the feature vector can be defined and this embedding can be learned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F418KsbgeMiz"
      },
      "source": [
        "### Text vectorization (tokenization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmDCHzgPeRPi",
        "outputId": "59663839-719d-4b28-d1b4-82ad2f584238"
      },
      "source": [
        "train_sentences[:5]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "       'Imagine getting flattened by Kurt Zouma',\n",
              "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "       \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "       'Somehow find you and I collide http://t.co/Ee8RpOahPk'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JMd2f1QeSkz"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "# Use the default TextVectorization parameters\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens = None, # how many words in the vocab (automatically add <OOV>)\n",
        "                                    standardize = \"lower_and_strip_punctuation\",\n",
        "                                    split = \"whitespace\", \n",
        "                                    ngrams = None,\n",
        "                                    output_mode = \"int\", #how to map tokens to numbers\n",
        "                                    output_sequence_length = None, #pads each sequence to the logest sequence\n",
        "                                    pad_to_max_tokens = True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2DSXz93fNcV",
        "outputId": "93bcf33b-9fbc-4a19-961a-664f53cfd078"
      },
      "source": [
        "# Find the average number of tokens (words) in the training tweets\n",
        "\n",
        "round(sum(len(i.split()) for i in train_sentences)) / len(train_sentences)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14.901036345059115"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PyZrrwPhe4U"
      },
      "source": [
        "# Setup text vectorization variables\n",
        "\n",
        "max_vocab_length = 10000 #max num of words to have in our vocabulary\n",
        "max_length = 15 # max length our seuqences will be (how many words in a tweet, amodel would see)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens = max_vocab_length, output_mode= 'int', output_sequence_length = max_length)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDVzTznLiDwm"
      },
      "source": [
        "#fit the text vectorier to the training text\n",
        "\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKIukLPgmz5A",
        "outputId": "2007c802-c4eb-475f-eb2a-ff07e4e8afed"
      },
      "source": [
        "# Create a sample sentence and tokenize it\n",
        "\n",
        "sample_sentence = \"Theres a flood in my street!\"\n",
        "\n",
        "text_vectorizer([sample_sentence])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Td3xFgCnGfD",
        "outputId": "03606407-afa0-40f6-f393-1202c8ee3ac3"
      },
      "source": [
        "# Choose a random sentence from the training dataset and tokenize iot\n",
        "\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n {random_sentence}\\n\\nVectorized version:\")\n",
        "text_vectorizer([random_sentence])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original text:\n",
            " 'If you go on with this nuclear arms race all you are going to do is make the rubble bounce.' ? Winston Churchill\n",
            "\n",
            "Vectorized version:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[  47,   12,  112,   11,   14,   19,  105, 2192, 2768,   44,   12,\n",
              "          22,  104,    5,   68]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjEI87-Mnpiw",
        "outputId": "05f6f517-f79f-45e2-8564-30b313cf69a9"
      },
      "source": [
        "# Get the unique words in the vocabulary\n",
        "\n",
        "words_in_vocab = text_vectorizer.get_vocabulary() #get all of the unique words in the training data\n",
        "top_5_words = words_in_vocab[:5] # get the most common words\n",
        "bottom_5_words = words_in_vocab[-5:] #get the least common words\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f\"5 most comon words: {top_5_words}\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in vocab: 10000\n",
            "5 most comon words: ['', '[UNK]', 'the', 'a', 'in']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWW769H8pF-8"
      },
      "source": [
        "### Creating an Embedding using an Embedding Layer\n",
        "\n",
        "To make our embedding, we're going to use tensoflows embedding layer\n",
        "\n",
        "The parameters we actually care about:\n",
        "* `input_dim` = the size of our vocabulary\n",
        "* `output_dim` = the size of the output embedding vector, for example, a value of 100 would mean each token gets represented by a vecotr 100 long\n",
        "* `input_length` = length of the sequences being passed to the embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5B7iSg3Ep7iT",
        "outputId": "85231a14-e3cb-45b7-fb09-911ae50770b4"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "# in keras, wordks best when numbers are divisible by eight\n",
        "\n",
        "embedding = layers.Embedding(input_dim = max_vocab_length,\n",
        "                             output_dim = 128,\n",
        "                             input_length = max_length\n",
        "                             )\n",
        "embedding"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.embeddings.Embedding at 0x7f01629c5550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbX5XRVfrNRv",
        "outputId": "03294d65-f32e-4356-a09a-94470d5c1f02"
      },
      "source": [
        "# Get a random sentence from the training set\n",
        "\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n {random_sentence}\\n\\nEmbedded version:\")\n",
        "\n",
        "# Embed the random sentence (turn into dense vecotrs of fixed size)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original text:\n",
            " @Epic_Insanity It got derailed outside Grimrail Depot...\n",
            "\n",
            "Embedded version:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[ 0.01047666, -0.04618541,  0.00207051, ..., -0.03424738,\n",
              "          0.01741663,  0.01074405],\n",
              "        [-0.03328212,  0.00590597,  0.02693787, ...,  0.00047261,\n",
              "         -0.02006059,  0.024491  ],\n",
              "        [-0.03996246, -0.04608276,  0.01444763, ..., -0.01359117,\n",
              "          0.01808906,  0.03372772],\n",
              "        ...,\n",
              "        [ 0.04286379,  0.00187195,  0.04902841, ...,  0.0480523 ,\n",
              "         -0.01340004, -0.02682008],\n",
              "        [ 0.04286379,  0.00187195,  0.04902841, ...,  0.0480523 ,\n",
              "         -0.01340004, -0.02682008],\n",
              "        [ 0.04286379,  0.00187195,  0.04902841, ...,  0.0480523 ,\n",
              "         -0.01340004, -0.02682008]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atTvotyfryMA",
        "outputId": "30f2b915-a220-4b11-9535-17802557220b"
      },
      "source": [
        "# Chekc out a single token's embedding\n",
        "\n",
        "sample_embed[0][0], sample_embed[0][0].shape, random_sentence[0]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              " array([ 0.01047666, -0.04618541,  0.00207051, -0.01999754, -0.04905098,\n",
              "         0.04015628,  0.02418551, -0.03234537,  0.00053991,  0.00679702,\n",
              "         0.00191369,  0.0440807 ,  0.00900842,  0.0152978 ,  0.03850639,\n",
              "         0.02259849, -0.01668298,  0.04545177, -0.02773161,  0.02805177,\n",
              "         0.03645641,  0.02132385,  0.0216934 ,  0.04798469,  0.02672093,\n",
              "         0.04031323, -0.03660306,  0.04878786,  0.04746426, -0.02749999,\n",
              "         0.0021134 ,  0.0372741 , -0.00900165, -0.01320041,  0.02958525,\n",
              "         0.04388133, -0.04145175, -0.01107869,  0.0428392 , -0.03554166,\n",
              "         0.03062192,  0.03238335,  0.02182421,  0.02241507, -0.00072523,\n",
              "         0.02374176,  0.00877333, -0.00794033, -0.04222196,  0.01164725,\n",
              "         0.03418603,  0.00998669,  0.02106657,  0.00259709,  0.0296754 ,\n",
              "         0.01083484,  0.01395942, -0.01072314, -0.00509969,  0.04971688,\n",
              "        -0.00755472,  0.01016914,  0.02416697, -0.01494027, -0.00268295,\n",
              "         0.03805408,  0.04286362,  0.03735116,  0.02053213,  0.00501435,\n",
              "        -0.02532675,  0.02651218,  0.00962787,  0.01880581, -0.04533307,\n",
              "         0.01131755, -0.00258873, -0.0498414 , -0.03423786, -0.00221355,\n",
              "        -0.01706053,  0.01673253, -0.03123436, -0.03192189, -0.02170563,\n",
              "        -0.03173852,  0.0174909 , -0.00200539, -0.03786965, -0.03730768,\n",
              "         0.02536607, -0.04380718,  0.02868864, -0.00040079, -0.03589524,\n",
              "         0.01105449,  0.04501574,  0.03515008, -0.0099799 ,  0.04922462,\n",
              "        -0.03478484, -0.01909818, -0.04695074, -0.02109314, -0.04058828,\n",
              "        -0.02700409,  0.02324859,  0.01141828, -0.02086145,  0.00979973,\n",
              "         0.03229151, -0.02202706, -0.00733496, -0.04868692,  0.04815718,\n",
              "         0.03310883, -0.00776632,  0.03701482,  0.01037502, -0.04075378,\n",
              "         0.03486841,  0.02605141, -0.04529712,  0.01162056, -0.04947696,\n",
              "        -0.03424738,  0.01741663,  0.01074405], dtype=float32)>,\n",
              " TensorShape([128]),\n",
              " '@')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtMpeo5YsY9x"
      },
      "source": [
        "## Modelling a text dataset (running a series of experiments)\n",
        "\n",
        "Now we're got a wat to turn our text srequences into numbers, it's time to start building a series of modelling experiments, start from a baseline and move on from there \n",
        "\n",
        "* Model 0: Naive Bayes (baseline)\n",
        "* Model 1: Feed-forward neual network (dense model)\n",
        "* Model 2: GRU model (RNN)\n",
        "* Model 4: Bidirectional-LSTM\n",
        "* Model 5: 1d Convolutional Neural Network (CNN)\n",
        "* Model 6: Tensorflow Hub Pretrained Geature Extractor (using transfer learning for NLP)\n",
        "* Model 7: Same as model 6 with 10% of training data\n",
        "\n",
        "How are we going to approach all of these?\n",
        "\n",
        "Use the standard steps in modelling with tensorflow:\n",
        "\n",
        "* Create a model\n",
        "* Build a model\n",
        "* Compile a model\n",
        "* Fit the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRqK9DU2zyOB"
      },
      "source": [
        "### Model 0: Getting a baseline\n",
        "\n",
        "As with all machine learning modelling experiments it's important to create a baseline model so u got a benchmark for future experiments to build upon\n",
        "\n",
        "To create our baseline, we'll use SKlearns Multinomial Naive Bayes using the TF-IDF formula to convert our words to numbers\n",
        "\n",
        "> **Note:** It's common practive to use non-DL algorithms as a baseline because of their speed, then later using DL to improve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXHA03tu11fw",
        "outputId": "af94fa1f-0d5f-460f-bd1c-c09e4992da5e"
      },
      "source": [
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "\n",
        "model_0 = Pipeline([\n",
        "                    (\"tfidf\", TfidfVectorizer()),\n",
        "                    (\"clf\", MultinomialNB())\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0pGO_Cu2nOz",
        "outputId": "71ce8fe9-ec50-488c-c7d9-1baa3988f470"
      },
      "source": [
        "# Evaluate our baseline model \n",
        "\n",
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our baseline model achieves an accuracy of: 79.27%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sgfvxx5KM1Qi",
        "outputId": "56f87c9f-f555-488d-abf6-3b6a9e83a127"
      },
      "source": [
        "# Make predictions\n",
        "\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxtyEbMaM20B"
      },
      "source": [
        "### Creating an evaluation function for our model experiments\n",
        "\n",
        "We could evaluate model's predictin with different methods every time, but this could be cumbersome and could easily be fixed with a function\n",
        "\n",
        "Let's create one to compare our model's predictions with the truth labels using the following metrics:\n",
        "\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Do39oLkhOEnq"
      },
      "source": [
        "# Function to evaluate: accuracty, precision, recall, f1-score\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calulates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "  \"\"\"\n",
        "  #Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  #Calculate model precision, recall ,and f01 score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average = 'weighted')\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                   \"precision\": model_precision,\n",
        "                   \"recall\": model_recall,\n",
        "                   \"f1\": model_f1}\n",
        "  return model_results"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfl1-F8APlG3",
        "outputId": "33dbc0d1-4083-4ff1-9d64-e8fc10013397"
      },
      "source": [
        "baseline_results = calculate_results(y_true = val_labels, y_pred = baseline_preds)\n",
        "\n",
        "baseline_results"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk1ExNgnPsj0"
      },
      "source": [
        "### Model 1: A simple dense model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoWkXelQSLHU"
      },
      "source": [
        "# Create a tensorboard callback (need to create a new one for each model)\n",
        "\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create a directory to save TensorBoard logs\n",
        "\n",
        "SAVE_DIR = \"model_logs\""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-XbEZowS21l"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape = (1,), dtype = tf.string) # inputs are 1-dimensional\n",
        "x = text_vectorizer(inputs) # turn the input text into numbers\n",
        "x = embedding(x) # create an embedding of the numberized imputs\n",
        "x = layers.GlobalAveragePooling1D()(x) # condense the feature vector for each token to one vector\n",
        "#x = layers.GlobalMaxPool1D()(x)\n",
        "outputs = layers.Dense(1, activation = \"sigmoid\")(x) # Create the output layer, want binary output so use sigmoid\n",
        "\n",
        "model_1 = tf.keras.Model(inputs, outputs, name = \"model_1_dense\")"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_cQ031LTiWo",
        "outputId": "5d33f605-cea3-4cd4-c033-d7f4433762f3"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSg-pNTrTnQI"
      },
      "source": [
        "# Compile mode\n",
        "\n",
        "model_1.compile(loss = \"binary_crossentropy\", optimizer = tf.keras.optimizers.Adam(), metrics = [\"accuracy\"])"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuxtV74lUB3P",
        "outputId": "d3ba2d8e-6298-491b-9094-c334ac7b037f"
      },
      "source": [
        "# Fit the mode\n",
        "model_1_history = model_1.fit(x = train_sentences, y = train_labels, epochs = 15, validation_data = (val_sentences, val_labels),\n",
        "                              callbacks = [create_tensorboard_callback(dir_name = SAVE_DIR, experiment_name = \"model_1_dense\")])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_1_dense/20210526-194301\n",
            "Epoch 1/15\n",
            "215/215 [==============================] - 7s 17ms/step - loss: 0.6092 - accuracy: 0.6910 - val_loss: 0.5352 - val_accuracy: 0.7507\n",
            "Epoch 2/15\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.4408 - accuracy: 0.8213 - val_loss: 0.4733 - val_accuracy: 0.7822\n",
            "Epoch 3/15\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.3468 - accuracy: 0.8597 - val_loss: 0.4605 - val_accuracy: 0.7940\n",
            "Epoch 4/15\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.2840 - accuracy: 0.8924 - val_loss: 0.4671 - val_accuracy: 0.7927\n",
            "Epoch 5/15\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.2370 - accuracy: 0.9124 - val_loss: 0.4795 - val_accuracy: 0.7769\n",
            "Epoch 6/15\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.2005 - accuracy: 0.9264 - val_loss: 0.5025 - val_accuracy: 0.7848\n",
            "Epoch 7/15\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.1714 - accuracy: 0.9416 - val_loss: 0.5307 - val_accuracy: 0.7874\n",
            "Epoch 8/15\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.1491 - accuracy: 0.9498 - val_loss: 0.5552 - val_accuracy: 0.7795\n",
            "Epoch 9/15\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.1304 - accuracy: 0.9553 - val_loss: 0.5816 - val_accuracy: 0.7822\n",
            "Epoch 10/15\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.1151 - accuracy: 0.9615 - val_loss: 0.6152 - val_accuracy: 0.7782\n",
            "Epoch 11/15\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.1040 - accuracy: 0.9654 - val_loss: 0.6540 - val_accuracy: 0.7690\n",
            "Epoch 12/15\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0947 - accuracy: 0.9686 - val_loss: 0.6750 - val_accuracy: 0.7730\n",
            "Epoch 13/15\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0857 - accuracy: 0.9704 - val_loss: 0.7143 - val_accuracy: 0.7782\n",
            "Epoch 14/15\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0794 - accuracy: 0.9734 - val_loss: 0.7491 - val_accuracy: 0.7664\n",
            "Epoch 15/15\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0752 - accuracy: 0.9731 - val_loss: 0.7732 - val_accuracy: 0.7703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rnWsIXiUqJH",
        "outputId": "b83f089d-6bdd-4620-d324-a870f6d5c9c4"
      },
      "source": [
        "# Check the results\n",
        "\n",
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 0s 3ms/step - loss: 0.7732 - accuracy: 0.7703\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7732366323471069, 0.7703412175178528]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nA2JFJFKVJKr",
        "outputId": "f49bf4da-b65b-4479-b164-984382da262e"
      },
      "source": [
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_pred_probs.shape"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(762, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSifuWJpVSX-",
        "outputId": "dd29bc78-f2ba-4934-89bb-a6e4c896588a"
      },
      "source": [
        "# look at a single prediction\n",
        "\n",
        "model_1_pred_probs[0] # anything below 0.5 = disaster, abouve = non-=disaster"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.480202], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2rmcAjIVlOJ",
        "outputId": "95148cc1-bdc9-445d-f6c6-2e758115e93c"
      },
      "source": [
        "# look at the first 10 predictions\n",
        "\n",
        "model_1_pred_probs[:10]"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.480202  ],\n",
              "       [0.8405013 ],\n",
              "       [0.99907374],\n",
              "       [0.08197001],\n",
              "       [0.00123418],\n",
              "       [0.98816645],\n",
              "       [0.8344143 ],\n",
              "       [0.99998295],\n",
              "       [0.99994135],\n",
              "       [0.73105735]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwrMHbtGXwsm",
        "outputId": "d617855b-73cd-4c9e-9a42-4d11fe9a6bb1"
      },
      "source": [
        "# Convert model prediction probablilities to label format\n",
        "\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
        "\n",
        "model_1_preds[:20]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-X-TB_QbXz17",
        "outputId": "ca16f9d4-1f32-427a-92bb-93e394c06096"
      },
      "source": [
        "# calculate our model_1 results\n",
        "\n",
        "model_1_results = calculate_results(y_true = val_labels, y_pred = model_1_preds)\n",
        "\n",
        "model_1_results"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.03412073490814,\n",
              " 'f1': 0.7684486602580174,\n",
              " 'precision': 0.7715893693867238,\n",
              " 'recall': 0.7703412073490814}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2nYRPQaYP1Y",
        "outputId": "8211a602-b73b-419d-927f-dc552228bbe2"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiA058ZOYZM8",
        "outputId": "5722e95c-54e6-42f1-9642-3f309fa9cf7e"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjAm6su5Yg7P"
      },
      "source": [
        "# Visualizing learned embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lJJQMSjcoyn",
        "outputId": "a2b49f3d-b114-4755-d133-d19b7f4833e7"
      },
      "source": [
        "# get the vocab from the text vecotrization layer\n",
        "\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab), words_in_vocab[:10]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zPleCXFc0tT",
        "outputId": "c3ad5f40-f93d-4603-be43-0c7a55c888b7"
      },
      "source": [
        "# Model 1 summary\n",
        "\n",
        "model_1.summary()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXdj67FGc7uI",
        "outputId": "68464013-11e5-47a0-eb41-f5c555dbe336"
      },
      "source": [
        "# Get the wieght matrix of embedding layer\n",
        "# (these are the numerical representations of each token in our training data, which have been learned for 5 epocks)\n",
        "\n",
        "embed_weights = model_1.get_layer(\"embedding\").get_weights()[0]\n",
        "\n",
        "print(embed_weights.shape) # same size as vocab size and embedding dim (output dim of our embedding layer)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Qa_btGodOS2",
        "outputId": "225b74b3-2979-46fb-a2b0-759b9e607688"
      },
      "source": [
        "embed_weights"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.03287848, -0.01077829,  0.0398485 , ...,  0.05907033,\n",
              "        -0.00235764, -0.03854776],\n",
              "       [ 0.00970599, -0.04863368,  0.00415329, ..., -0.03332829,\n",
              "         0.01916864,  0.00813477],\n",
              "       [-0.01269921, -0.03966425, -0.04843201, ..., -0.01803764,\n",
              "        -0.02748964, -0.00289053],\n",
              "       ...,\n",
              "       [ 0.0262516 ,  0.01350881,  0.02646807, ...,  0.01978141,\n",
              "         0.046014  , -0.03561642],\n",
              "       [-0.06411702, -0.06825753, -0.06583641, ...,  0.05338053,\n",
              "         0.02562852, -0.03883247],\n",
              "       [-0.13784286, -0.10867371, -0.18086028, ...,  0.18514158,\n",
              "         0.14909989, -0.11820889]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zn-KB6CeENH"
      },
      "source": [
        "# Create embedding files\n",
        "\n",
        "import io\n",
        "\n",
        "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "#for index, word in enumerate(words_in_vocab):\n",
        "  #if index == 0:\n",
        "   # continue  # skip 0, it's padding.\n",
        "  #vec = embed_weights[index]\n",
        "  #out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "  #out_m.write(word + \"\\n\")\n",
        "#out_v.close()\n",
        "#out_m.close()"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlVDL_N6gJh0"
      },
      "source": [
        "# Download files from Colab to upload to projector\n",
        "\n",
        "#try:\n",
        "  #from google.colab import files\n",
        "  #files.download('vectors.tsv')\n",
        "  #files.download('metadata.tsv')\n",
        "#except Exception:\n",
        "  #pass"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ_UVZS3h49-"
      },
      "source": [
        "## Recurrent Neural Networks (RNN's)\n",
        "\n",
        "RNN's are usefull for sequence data.\n",
        "\n",
        "The premise of a recurrent neural network is to use the representation of a previous input to aid the respresentation of a later input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OG51RgqrkL_i"
      },
      "source": [
        "### Model 2: LSTM\n",
        "\n",
        "LSTM = ling short term memory (one of the most popular LSTM cells)\n",
        "\n",
        "Our structure of an RNN typically looks like this:\n",
        "\n",
        "'''\n",
        "Input (text) -> Tokenize -> EMbedding -> Layers (RNN's/dense) -> Output (label probability)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cETGrbncmi3S",
        "outputId": "7f5acbb3-4287-4e19-ba89-4d99ab98e12f"
      },
      "source": [
        "# Create an LSTM model\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape = (1,), dtype = \"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "print(x.shape)\n",
        "#x = layers.LSTM(64, return_sequences = True)(x)\n",
        "print(x.shape)\n",
        "x = layers.LSTM(64)(x) # when you're stacking RNN cells together, you need to return_sequences = true\n",
        "print(x.shape)\n",
        "#x = layers.Dense(64, activation = 'relu')(x)\n",
        "outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
        "\n",
        "model_2 = tf.keras.Model(inputs, outputs, name = \"model_2_LSTM\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 15, 128)\n",
            "(None, 15, 128)\n",
            "(None, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79605SQcnqeV"
      },
      "source": [
        "# Compile the model\n",
        "\n",
        "model_2.compile(loss = \"binary_crossentropy\", optimizer = tf.keras.optimizers.Adam(), metrics = [\"accuracy\"])"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHXEu-0cp8zz",
        "outputId": "84808a0d-1272-4779-dfde-23e331715b62"
      },
      "source": [
        "model_2_history = model_2.fit(train_sentences, train_labels, epochs = 5, \n",
        "                              validation_data = (val_sentences, val_labels), callbacks = [create_tensorboard_callback(SAVE_DIR, \"model_2_LSTM\")])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_2_LSTM/20210526-194425\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 10s 22ms/step - loss: 0.1188 - accuracy: 0.9657 - val_loss: 0.8207 - val_accuracy: 0.7664\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.0673 - accuracy: 0.9740 - val_loss: 0.9200 - val_accuracy: 0.7717\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.0624 - accuracy: 0.9774 - val_loss: 0.9336 - val_accuracy: 0.7664\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.0581 - accuracy: 0.9759 - val_loss: 1.0934 - val_accuracy: 0.7664\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.0494 - accuracy: 0.9775 - val_loss: 1.0036 - val_accuracy: 0.7598\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onlOd71jqSUk",
        "outputId": "288442a9-f80d-4398-c0ad-64b9fc7f06fe"
      },
      "source": [
        "# Make predictions with LSTM model\n",
        "\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs[:10]\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.07230075e-01],\n",
              "       [7.59281218e-01],\n",
              "       [9.96703804e-01],\n",
              "       [2.07418561e-01],\n",
              "       [2.94627709e-04],\n",
              "       [9.95440841e-01],\n",
              "       [2.77492911e-01],\n",
              "       [9.99923110e-01],\n",
              "       [9.99914646e-01],\n",
              "       [9.86454308e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZN3iCEO1qgCv",
        "outputId": "af56f4fa-8cb3-403a-ded4-97575b6b8e85"
      },
      "source": [
        "# Convert model 2 pred probs to labels\n",
        "\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 0., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iObNULydqupq",
        "outputId": "78d2bb3e-c8f0-4f19-a0d9-b62c94640990"
      },
      "source": [
        "model_2_results = calculate_results(y_true = val_labels, y_pred = model_2_preds)\n",
        "model_2_results"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.98425196850394,\n",
              " 'f1': 0.758116023760764,\n",
              " 'precision': 0.7604578907479682,\n",
              " 'recall': 0.7598425196850394}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DD12TyWtq4aN"
      },
      "source": [
        "### Model 3: GRU\n",
        "\n",
        "Another poppular and effective RNN component is the GRU or gated recurrent unit.\n",
        "\n",
        "The GRU cell has similar features to an LSTM cell but has less parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJ8-3EqZZw1r"
      },
      "source": [
        "# Build an RNN using the GRU cell\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape = (1,), dtype = tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.GRU(64)(x)\n",
        "#x = layers.LSTM(64, return_sequences = True)(x)\n",
        "#print(x.shape)\n",
        "#x = layers.GRU(64)(x) # make sure return seuqences DOES NO equal true OR add a global average pooling layer instead\n",
        "#x = layers.Dense(64, activation = \"relu\")(x)\n",
        "outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
        "\n",
        "\n",
        "model_3 = tf.keras.Model(inputs, outputs)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_sAuSwJayw0",
        "outputId": "eeee9636-83c2-4fdd-e16a-b3c8755925a4"
      },
      "source": [
        " model_3.summary(\n",
        "     \n",
        " )"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 64)                37248     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,317,313\n",
            "Trainable params: 1,317,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzKsHw9cdXIw"
      },
      "source": [
        "# COmpile the model\n",
        "\n",
        "model_3.compile(loss = \"binary_crossentropy\", optimizer= tf.keras.optimizers.Adam(), metrics = [\"accuracy\"])\n"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSCbPYG6eN5s",
        "outputId": "5c57e7fb-fa29-4424-9888-828eae734dd0"
      },
      "source": [
        "# Fit\n",
        "\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels, epochs = 10,\n",
        "                              validation_data = (val_sentences, val_labels),\n",
        "                              callbacks = [create_tensorboard_callback(SAVE_DIR, \"model_3_GRU\")])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_3_GRU/20210526-194508\n",
            "Epoch 1/10\n",
            "215/215 [==============================] - 6s 20ms/step - loss: 0.1249 - accuracy: 0.9520 - val_loss: 0.8516 - val_accuracy: 0.7651\n",
            "Epoch 2/10\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.0581 - accuracy: 0.9769 - val_loss: 0.9056 - val_accuracy: 0.7598\n",
            "Epoch 3/10\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0521 - accuracy: 0.9783 - val_loss: 0.8725 - val_accuracy: 0.7638\n",
            "Epoch 4/10\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.0483 - accuracy: 0.9793 - val_loss: 1.0823 - val_accuracy: 0.7598\n",
            "Epoch 5/10\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.0416 - accuracy: 0.9804 - val_loss: 1.1240 - val_accuracy: 0.7598\n",
            "Epoch 6/10\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.0396 - accuracy: 0.9810 - val_loss: 1.3030 - val_accuracy: 0.7703\n",
            "Epoch 7/10\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0403 - accuracy: 0.9806 - val_loss: 1.3386 - val_accuracy: 0.7625\n",
            "Epoch 8/10\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0405 - accuracy: 0.9804 - val_loss: 1.5787 - val_accuracy: 0.7703\n",
            "Epoch 9/10\n",
            "215/215 [==============================] - 3s 16ms/step - loss: 0.0342 - accuracy: 0.9832 - val_loss: 1.4674 - val_accuracy: 0.7743\n",
            "Epoch 10/10\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0326 - accuracy: 0.9837 - val_loss: 2.0389 - val_accuracy: 0.7677\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSkjpFQteet3",
        "outputId": "5eaef29e-858e-4d8b-c6bb-774c5779b5f2"
      },
      "source": [
        "# Make some predictions with GRu model\n",
        "\n",
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "model_3_pred_probs[:10]"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.3839268e-05],\n",
              "       [6.7373121e-01],\n",
              "       [9.9992394e-01],\n",
              "       [2.0152812e-01],\n",
              "       [1.2908875e-05],\n",
              "       [9.9995506e-01],\n",
              "       [9.9915314e-01],\n",
              "       [9.9998236e-01],\n",
              "       [9.9997246e-01],\n",
              "       [9.9984705e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghJcJReUe5tO",
        "outputId": "314917db-7087-43a6-f745-ca6cbe941253"
      },
      "source": [
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4v5s_uv1fGQP",
        "outputId": "19e979d3-4f62-46b9-b81a-f14325fe6e60"
      },
      "source": [
        "# Calculate model 3 results\n",
        "\n",
        "model_3_results = calculate_results(y_true = val_labels, y_pred = model_3_preds)\n",
        "model_3_results"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.77165354330708,\n",
              " 'f1': 0.7646846187166754,\n",
              " 'precision': 0.7712255031085189,\n",
              " 'recall': 0.7677165354330708}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1D746dtfSMl"
      },
      "source": [
        "### Model 4: Bidirectional RNN\n",
        "\n",
        "ormal RNN's go from left to right (just like you'd read an English sentence) however, a bidiractional RNN goes from right to left as well as left to right."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDlCN7e9Ngvm",
        "outputId": "4881f817-015b-4628-bcbc-db058785d0d5"
      },
      "source": [
        "# Build a dirirectional RNN in Tensorflow\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape = (1,), dtype = \"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "#x = layers.Bidirectional(layers.LSTM(64, return_sequences = True))(x)\n",
        "#print(x.shape)\n",
        "x = layers.Bidirectional(layers.GRU(64))(x)\n",
        "print(x.shape)\n",
        "outputs = layers.Dense(1, activation = 'sigmoid')(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name = \"model_4_bidirectional\")"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tTuzN-iP9zZ",
        "outputId": "b5e65eca-37ea-4503-caeb-99d8374e3dc7"
      },
      "source": [
        "# Get a summary\n",
        "\n",
        "model_4.summary()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4_bidirectional\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 128)               74496     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,354,625\n",
            "Trainable params: 1,354,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYniEnRpQW0i"
      },
      "source": [
        "# Compile model\n",
        "\n",
        "model_4.compile(loss = \"binary_crossentropy\", optimizer = tf.keras.optimizers.Adam(), metrics = ['accuracy'])"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COZ8O0IjRGUS",
        "outputId": "1551c220-94ea-48fa-edd6-6113bb1e9163"
      },
      "source": [
        "model_4_history = model_4.fit(train_sentences, train_labels, epochs = 5, validation_data = (val_sentences, val_labels), callbacks = [create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                                                                                                                 \"model_4_bidirectional\")])"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_4_bidirectional/20210526-194546\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 7s 23ms/step - loss: 0.0994 - accuracy: 0.9679 - val_loss: 1.0387 - val_accuracy: 0.7585\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.0470 - accuracy: 0.9801 - val_loss: 1.2397 - val_accuracy: 0.7572\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.0408 - accuracy: 0.9800 - val_loss: 1.2391 - val_accuracy: 0.7598\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.0360 - accuracy: 0.9813 - val_loss: 1.2790 - val_accuracy: 0.7625\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.0334 - accuracy: 0.9826 - val_loss: 1.3402 - val_accuracy: 0.7638\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBQCoT6TRXt7",
        "outputId": "8a621711-3def-45c1-ba47-6e033421693f"
      },
      "source": [
        "# Make predictions with out bidiractional ,odel\n",
        " \n",
        "model_4_pred_probs = model_4.predict(val_sentences)\n",
        "model_4_pred_probs[:10]"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8.7149558e-04],\n",
              "       [7.9716021e-01],\n",
              "       [9.9968314e-01],\n",
              "       [2.6114169e-01],\n",
              "       [2.5018046e-05],\n",
              "       [9.9976212e-01],\n",
              "       [9.7900140e-01],\n",
              "       [9.9997067e-01],\n",
              "       [9.9993122e-01],\n",
              "       [9.9914038e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E64d_cojSdDk",
        "outputId": "a5cc9a40-50e8-4dcc-d02a-8f7dd832b3a7"
      },
      "source": [
        "# Convert\n",
        "\n",
        "model_4_pred = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_pred[:10]"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lN1plTXBSupu",
        "outputId": "1e3c5eb0-88e8-4ebd-ad42-f5153262aa6f"
      },
      "source": [
        "# Calculate the results of our bidiractional model\n",
        "\n",
        "model_4_results = calculate_results(y_true = val_labels, y_pred = model_4_pred )\n",
        "model_4_results"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.37795275590551,\n",
              " 'f1': 0.7621412379223811,\n",
              " 'precision': 0.764383846466808,\n",
              " 'recall': 0.7637795275590551}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuhkIab5TCzL"
      },
      "source": [
        "### Model 5: Conv1D \n",
        "\n",
        "We've used CNNs for images but images are typically 2D (hegith x width)...however, our text data is 1d.\n",
        "\n",
        "The typical structure of a Conv1D model for sequen ces (in our case, text):\n",
        "\n",
        "```\n",
        "Inputs(test -> Tokenization -> Embedding -> Cpmv1D -> Pool -> Outputs (class probs)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpkmmIYJgzkP"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "input = layers.Input(shape = (1,), dtype = \"string\")\n",
        "x = text_vectorizer(input)\n",
        "x = embedding(x)\n",
        "x = layers.Conv1D(32, 6, activation = 'relu')(x) #kernal size is reffered to as n-gram side (strides rn is 1, but can change to hop) #padding = 'valid' (some words mised) output is smaller 'same' = smae size\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "output = layers.Dense(1, activation = \"sigmoid\")(x)\n",
        "\n",
        "model_5 = tf.keras.Model(input, output, name = \"model_5_conv\")\n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZtHFSyOhZHC",
        "outputId": "d7c610fe-a66c-4232-f349-ee81438289a3"
      },
      "source": [
        "model_5.summary()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5_conv\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 10, 32)            24608     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,304,641\n",
            "Trainable params: 1,304,641\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPkWqHezhad-"
      },
      "source": [
        "# Compiling the model\n",
        "\n",
        "model_5.compile(loss = 'binary_crossentropy', optimizer = tf.keras.optimizers.Adam(), metrics = ['accuracy'])\n",
        "\n"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SHFzy1JiXNo",
        "outputId": "d547f338-5159-4a99-dca4-142b8cd75eb0"
      },
      "source": [
        "# Fitting the model\n",
        "\n",
        "model_5_history = model_5.fit(train_sentences, train_labels, epochs = 5, \n",
        "                              validation_data = (val_sentences, val_labels), callbacks = [create_tensorboard_callback(SAVE_DIR, \"model_5_conv\")])"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_5_conv/20210526-194610\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 30s 20ms/step - loss: 0.1034 - accuracy: 0.9672 - val_loss: 1.0296 - val_accuracy: 0.7598\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0601 - accuracy: 0.9765 - val_loss: 1.1526 - val_accuracy: 0.7520\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0508 - accuracy: 0.9788 - val_loss: 1.2415 - val_accuracy: 0.7480\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0485 - accuracy: 0.9781 - val_loss: 1.3180 - val_accuracy: 0.7533\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0455 - accuracy: 0.9784 - val_loss: 1.3654 - val_accuracy: 0.7480\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXD2dzsVitE8",
        "outputId": "89bbae2e-5270-48f0-9c96-ce1d5169df35"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape = (1,), dtype = tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Conv1D(filters = 64, kernel_size = 5, activation = \"relu\")(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "#x = layers.Dense(64, activation = \"relu\")(x)\n",
        "outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
        "model_6 = tf.keras.Model(inputs, outputs, name = \"model_6_Conv1D\")\n",
        "\n",
        "model_6.compile(loss = \"binary_crossentropy\", optimizer = tf.keras.optimizers.Adam(), metrics = ['accuracy'])\n",
        "\n",
        "model_6.summary()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6_Conv1D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 11, 64)            41024     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,321,089\n",
            "Trainable params: 1,321,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ4us1g0acR2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "132baade-9997-4edd-c110-30836f598c9f"
      },
      "source": [
        "# Fit the model\n",
        "\n",
        "model_6_history = model_6.fit(train_sentences, train_labels, epochs = 5,\n",
        "                              validation_data = (val_sentences, val_labels), callbacks = [create_tensorboard_callback(SAVE_DIR, \"Conv1D\")])"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/Conv1D/20210526-194733\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 18ms/step - loss: 0.0772 - accuracy: 0.9750 - val_loss: 1.1440 - val_accuracy: 0.7559\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0485 - accuracy: 0.9783 - val_loss: 1.2864 - val_accuracy: 0.7507\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0443 - accuracy: 0.9804 - val_loss: 1.3164 - val_accuracy: 0.7493\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0435 - accuracy: 0.9807 - val_loss: 1.3506 - val_accuracy: 0.7415\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0423 - accuracy: 0.9807 - val_loss: 1.3858 - val_accuracy: 0.7493\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnQz5HN3bFC_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad758a23-b942-4a05-bb07-46a7675ca0c2"
      },
      "source": [
        "# Make some prediction with our Conv1D model\n",
        "\n",
        "model_6_pred_probs = model_6.predict(val_sentences)\n",
        "model_6_pred = tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_pred[:10]"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTgk7hA_bc3P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a55d935c-85ec-41b7-8738-ae94aecf3faa"
      },
      "source": [
        "model_6_results = calculate_results(y_true = val_labels, y_pred = model_6_pred)\n",
        "model_6_results"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 74.93438320209974,\n",
              " 'f1': 0.7474119306358412,\n",
              " 'precision': 0.749916614970861,\n",
              " 'recall': 0.7493438320209974}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppsrzXjOblG2"
      },
      "source": [
        "## Model6: Tensorflow Hub Pretrained Sentence Encoder\n",
        "\n",
        "Using transfer learning for NLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBYSG30aj5VG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdb2ed95-568c-477d-a2d9-a5f6e5f6fe30"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "embed_samples = embed([sample_sentence, \"When you call the use on a sentence, it utrns it into numbers\"])\n",
        "\n",
        "print(embed_samples[0][:50])"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[-0.01157027  0.0248591   0.02878048 -0.012715    0.03971538  0.0882776\n",
            "  0.02680985  0.05589838 -0.01068729 -0.00597292  0.00639323 -0.0181952\n",
            "  0.00030814  0.09105888  0.05874645 -0.03180628  0.01512474 -0.05162929\n",
            "  0.00991367 -0.06865346 -0.04209305  0.0267898   0.03011008  0.00321069\n",
            " -0.00337971 -0.04787356  0.02266719 -0.00985925 -0.04063613 -0.01292093\n",
            " -0.04666384  0.056303   -0.03949255  0.00517688  0.02495828 -0.07014441\n",
            "  0.02871508  0.04947684 -0.00633978 -0.08960193  0.02807117 -0.00808362\n",
            " -0.01360601  0.0599865  -0.10361787 -0.05195374  0.00232955 -0.0233253\n",
            " -0.03758105  0.03327729], shape=(50,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5w7iBrEokUJE"
      },
      "source": [
        "# transforms THE WHOLE sentence into a 512 dimensional vector"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh5lPd1dkiw2"
      },
      "source": [
        "# Create Keras Layer using the USE pretrained layer from tensorflow hub\n",
        "\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape = [],\n",
        "                                        dtype = tf.string,\n",
        "                                        trainable = False,\n",
        "                                        name = \"USE\")"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tq3xaldlzkI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f294151-b984-45db-9fbc-1b7033baa00b"
      },
      "source": [
        "# Create model using the sequenctial API\n",
        "\n",
        "model_7 = tf.keras.Sequential([\n",
        "    sentence_encoder_layer,\n",
        "    layers.Dense(64, activation = \"relu\"),\n",
        "    layers.Dense(1, activation = 'sigmoid', name = 'output_layer')\n",
        "], name = \"model_7_USE\")\n",
        "\n",
        "# Compile\n",
        "\n",
        "model_7.compile(loss = 'binary_crossentropy', optimizer = \n",
        "                tf.keras.optimizers.Adam(), metrics = ['accuracy'])\n",
        "\n",
        "model_7.summary()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7_USE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE (KerasLayer)             (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8Ex63gMmVJY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a43fc4ee-8ee2-4a50-a25a-3b9d484fe371"
      },
      "source": [
        "# Train a classifier on top of USE pretrained embeddings\n",
        "\n",
        "model_7_history = model_7.fit(train_sentences, train_labels, epochs = 15,\n",
        "                              validation_data = (val_sentences, val_labels), callbacks = [create_tensorboard_callback(SAVE_DIR, \"model_7_use\")])"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_7_use/20210526-194815\n",
            "Epoch 1/15\n",
            "215/215 [==============================] - 7s 23ms/step - loss: 0.5044 - accuracy: 0.7853 - val_loss: 0.4486 - val_accuracy: 0.7979\n",
            "Epoch 2/15\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.4157 - accuracy: 0.8158 - val_loss: 0.4401 - val_accuracy: 0.8071\n",
            "Epoch 3/15\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.4025 - accuracy: 0.8206 - val_loss: 0.4345 - val_accuracy: 0.8110\n",
            "Epoch 4/15\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.3946 - accuracy: 0.8256 - val_loss: 0.4326 - val_accuracy: 0.8123\n",
            "Epoch 5/15\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.3871 - accuracy: 0.8311 - val_loss: 0.4338 - val_accuracy: 0.8163\n",
            "Epoch 6/15\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.3811 - accuracy: 0.8318 - val_loss: 0.4332 - val_accuracy: 0.8136\n",
            "Epoch 7/15\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.3757 - accuracy: 0.8348 - val_loss: 0.4286 - val_accuracy: 0.8150\n",
            "Epoch 8/15\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.3687 - accuracy: 0.8361 - val_loss: 0.4295 - val_accuracy: 0.8189\n",
            "Epoch 9/15\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.3637 - accuracy: 0.8399 - val_loss: 0.4291 - val_accuracy: 0.8215\n",
            "Epoch 10/15\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.3571 - accuracy: 0.8416 - val_loss: 0.4329 - val_accuracy: 0.8123\n",
            "Epoch 11/15\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.3509 - accuracy: 0.8444 - val_loss: 0.4302 - val_accuracy: 0.8202\n",
            "Epoch 12/15\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.3447 - accuracy: 0.8483 - val_loss: 0.4375 - val_accuracy: 0.8136\n",
            "Epoch 13/15\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.3377 - accuracy: 0.8502 - val_loss: 0.4378 - val_accuracy: 0.8176\n",
            "Epoch 14/15\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.3315 - accuracy: 0.8555 - val_loss: 0.4353 - val_accuracy: 0.8215\n",
            "Epoch 15/15\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.3247 - accuracy: 0.8580 - val_loss: 0.4408 - val_accuracy: 0.8189\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07_q7_SwnPn4"
      },
      "source": [
        "model_7_pred_probs = model_7.predict(val_sentences)\n",
        "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
        "model_7_results = calculate_results(val_labels, model_7_preds)\n"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJ9Bej99oVc8"
      },
      "source": [
        "## Model8 :TF Hub Pretrained USE but with 10% of training data\n",
        "\n",
        "Transfer learning really helps when you don't have a alarge dataset.\n",
        "\n",
        "To see how our model performs on a smaller dataset, let's replicate 'model_& except we'll train it on 10% of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f-MxbE3snfu"
      },
      "source": [
        "# Create subset of 10% of the training data\n",
        "\n",
        "# NOte\n",
        "\n",
        "#train_10_percent = train_df_shuffled[[\"text\", \"target\"]].sample(frac = 0.1, random_state = 42)\n",
        "\n",
        "#train_sentences_10_percent = train_10_percent[\"text\"].to_list()\n",
        "#train_labels_10_percent = train_10_percent['target'].to_list()"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmZ-2W7jY7rp"
      },
      "source": [
        " **Note** Be *very* carefule when creating training/va;/test splits that you don't leak data across the datasets, otherwise your model evaluation metrics will be wrong. If something looks to good to be true (a model trainied on 10 percent of data doutperforming a mdel trained on100% of the data) trust your gut and o back thorugh to find where the error may lie."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeTJMXTpWylo"
      },
      "source": [
        "train_10_percent_split = int(0.1* len(train_sentences))\n",
        "train_10_percent = train_sentences[:train_10_percent_split]\n",
        "train_labels_10_percent =  train_labels[:train_10_percent_split]"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEJJVzBTX2DY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a9be8b0-e0ed-4977-bae5-466fecb59fc6"
      },
      "source": [
        "pd.Series(np.array(train_labels_10_percent)).value_counts()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    406\n",
              "1    279\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgW5Gq5js11i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "652ea463-608c-4d2b-a856-4883080cde58"
      },
      "source": [
        "# Check the number of target in our subset of data (ensure ratios are relatively close)\n",
        "\n",
        "train_df_shuffled[\"target\"].value_counts()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuI1t0ZFtdo3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8da3e3bf-ce54-4000-e977-e4fa9774aefc"
      },
      "source": [
        "train_df_shuffled['target'].value_counts()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTct5J0Asrbx"
      },
      "source": [
        "To recreeate amodel the same as a previous model you've created, you can use the 'tf.keras.models.clone_model ' method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFkKO83Dth3D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d49b50a6-0517-4d04-c8ae-d3c8593aea24"
      },
      "source": [
        "# Let's build a nodel the same as model_6\n",
        "\n",
        "model_8 = tf.keras.models.clone_model(model_7)\n",
        "\n",
        "model_8.compile(loss = 'binary_crossentropy', optimizer= tf.keras.optimizers.Adam(), metrics = ['accuracy'])\n",
        "\n",
        "model_8.summary()"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7_USE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE (KerasLayer)             (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_T64eabtTCp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a585889c-6ae0-421c-ac8e-b5aec595ddd1"
      },
      "source": [
        "# Fit the model on 10% training data\n",
        "\n",
        "model_8_history = model_8.fit(train_10_percent, train_labels_10_percent, epochs = 5,\n",
        "                              validation_data = (val_sentences, val_labels), callbacks = [create_tensorboard_callback(SAVE_DIR, 'model_8_correct_split')])"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_8_correct_split/20210526-194857\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 4s 114ms/step - loss: 0.6758 - accuracy: 0.6526 - val_loss: 0.6511 - val_accuracy: 0.7310\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.6038 - accuracy: 0.8015 - val_loss: 0.5942 - val_accuracy: 0.7598\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 1s 24ms/step - loss: 0.5279 - accuracy: 0.8117 - val_loss: 0.5389 - val_accuracy: 0.7717\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.4656 - accuracy: 0.8292 - val_loss: 0.5042 - val_accuracy: 0.7717\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.4242 - accuracy: 0.8307 - val_loss: 0.4910 - val_accuracy: 0.7677\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxkgcfaGuCea"
      },
      "source": [
        "model_8_pred_probs = model_8.predict(val_sentences)\n",
        "\n",
        "model_8_preds = tf.squeeze(tf.round(model_8_pred_probs))\n",
        "\n",
        "model_8_results = calculate_results(val_labels, model_8_preds)\n",
        "\n",
        "#print(results)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaVQDHuru9gB"
      },
      "source": [
        "## Comparing the performance of each of our models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-65Ybm8eZqfY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "7da27d8a-90eb-4a7c-bac6-a82b6805fe7e"
      },
      "source": [
        "# Combine model results into a Datafrmae \n",
        "\n",
        "all_model_results = pd.DataFrame({\"0_baseline\": baseline_results, \"1_simple_dense\": model_1_results,\n",
        "                                  \"2_lstm\": model_2_results, \"3_gru\": model_3_results,\n",
        "                                  \"4_bidirectional\": model_4_results, \"5_conv1d\": model_6_results, \n",
        "                                  \"6_tf_hub_use_encoder\": model_7_results, \n",
        "                                  \"7_tf_hub_use_encoder_10_percent\":model_8_results})\n",
        "all_model_results"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0_baseline</th>\n",
              "      <th>1_simple_dense</th>\n",
              "      <th>2_lstm</th>\n",
              "      <th>3_gru</th>\n",
              "      <th>4_bidirectional</th>\n",
              "      <th>5_conv1d</th>\n",
              "      <th>6_tf_hub_use_encoder</th>\n",
              "      <th>7_tf_hub_use_encoder_10_percent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>accuracy</th>\n",
              "      <td>79.265092</td>\n",
              "      <td>77.034121</td>\n",
              "      <td>75.984252</td>\n",
              "      <td>76.771654</td>\n",
              "      <td>76.377953</td>\n",
              "      <td>74.934383</td>\n",
              "      <td>81.889764</td>\n",
              "      <td>76.771654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.771589</td>\n",
              "      <td>0.760458</td>\n",
              "      <td>0.771226</td>\n",
              "      <td>0.764384</td>\n",
              "      <td>0.749917</td>\n",
              "      <td>0.823311</td>\n",
              "      <td>0.768688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.770341</td>\n",
              "      <td>0.759843</td>\n",
              "      <td>0.767717</td>\n",
              "      <td>0.763780</td>\n",
              "      <td>0.749344</td>\n",
              "      <td>0.818898</td>\n",
              "      <td>0.767717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1</th>\n",
              "      <td>0.786219</td>\n",
              "      <td>0.768449</td>\n",
              "      <td>0.758116</td>\n",
              "      <td>0.764685</td>\n",
              "      <td>0.762141</td>\n",
              "      <td>0.747412</td>\n",
              "      <td>0.816825</td>\n",
              "      <td>0.765926</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           0_baseline  ...  7_tf_hub_use_encoder_10_percent\n",
              "accuracy    79.265092  ...                        76.771654\n",
              "precision    0.811139  ...                         0.768688\n",
              "recall       0.792651  ...                         0.767717\n",
              "f1           0.786219  ...                         0.765926\n",
              "\n",
              "[4 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCqHw-QOZ5-X"
      },
      "source": [
        "## Uploading model's training logs to TensorBoard.dev"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XEmWBf6c3Yn",
        "outputId": "f3012939-960d-4541-fcc6-952b4d065588"
      },
      "source": [
        "!tensorboard dev upload --logdir ./model_logs/ \\\n",
        " --name \"NLP Modelling Experiments\" \\\n",
        " --description \"comparing model architectures\" \\\n",
        " --one_shot # exit the uploader once finished"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-26 19:49:06.940058: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "\n",
            "***** TensorBoard Uploader *****\n",
            "\n",
            "This will upload your TensorBoard logs to https://tensorboard.dev/ from\n",
            "the following directory:\n",
            "\n",
            "./model_logs/\n",
            "\n",
            "This TensorBoard will be visible to everyone. Do not upload sensitive\n",
            "data.\n",
            "\n",
            "Your use of this service is subject to Google's Terms of Service\n",
            "<https://policies.google.com/terms> and Privacy Policy\n",
            "<https://policies.google.com/privacy>, and TensorBoard.dev's Terms of Service\n",
            "<https://tensorboard.dev/policy/terms/>.\n",
            "\n",
            "This notice will not be shown again while you are logged into the uploader.\n",
            "To log out, run `tensorboard dev auth revoke`.\n",
            "\n",
            "Continue? (yes/NO) yes\n",
            "\n",
            "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=373649185512-8v619h5kft38l4456nm2dj4ubeqsrvh6.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email&state=hmzaAOxNvBVQJeh1bVrlIRAp0HClC4&prompt=consent&access_type=offline\n",
            "Enter the authorization code: Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/tensorboard\", line 8, in <module>\n",
            "    sys.exit(run_main())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorboard/main.py\", line 46, in run_main\n",
            "    app.run(tensorboard.main, flags_parser=tensorboard.configure)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 303, in run\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 251, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorboard/program.py\", line 276, in main\n",
            "    return runner(self.flags) or 0\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorboard/uploader/uploader_subcommand.py\", line 654, in run\n",
            "    return _run(flags, self._experiment_url_callback)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorboard/uploader/uploader_subcommand.py\", line 96, in _run\n",
            "    credentials = flow.run(force_console=flags.auth_force_console)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorboard/uploader/auth.py\", line 181, in run\n",
            "    return self.run_console()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/google_auth_oauthlib/flow.py\", line 412, in run_console\n",
            "    code = input(authorization_code_message)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyV3aItLdcoL"
      },
      "source": [
        "Now I've ran the cell above, my modelling experiments are visable on TensorBoard.dev:\n",
        "\n",
        "for larger sclae experiment and more tracking options, check out weights and biases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2_lihULeOHb",
        "outputId": "da70ef66-89bf-44db-b105-e7c5305724ab"
      },
      "source": [
        "# If you need to delete an experiment from TensorBoard, you can run the following:\n",
        "\n",
        "# See the previous Tensorboard Dev experiments you've run\n",
        "\n",
        "!tensorboard dev list"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-26 19:51:40.574356: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "\n",
            "***** TensorBoard Uploader *****\n",
            "\n",
            "This will list all experiments that you've uploaded to\n",
            "https://tensorboard.dev. TensorBoard.dev experiments are visible\n",
            "to everyone. Do not upload sensitive data.\n",
            "\n",
            "Your use of this service is subject to Google's Terms of Service\n",
            "<https://policies.google.com/terms> and Privacy Policy\n",
            "<https://policies.google.com/privacy>, and TensorBoard.dev's Terms of Service\n",
            "<https://tensorboard.dev/policy/terms/>.\n",
            "\n",
            "This notice will not be shown again while you are logged into the uploader.\n",
            "To log out, run `tensorboard dev auth revoke`.\n",
            "\n",
            "Continue? (yes/NO) Traceback (most recent call last):\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oVPDhqWfgVP"
      },
      "source": [
        "# !tensorboard dev delete --exmerimetn_id (take id)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM_LsTQUM0Fc"
      },
      "source": [
        "## Saving and loadsing a trained model\n",
        "\n",
        "There are two main formats to save a model to in Tensorflow:\n",
        "1. The HDF5 format\n",
        "2. The `SavedModel` format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAGB6Du-NJp4"
      },
      "source": [
        "# Save TF Hub Sentence Encoder model to HDF5 format\n",
        "\n",
        "model_7.save(\"model_7.h5\")"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "1TGU8wnPNbT6",
        "outputId": "779aa1c0-b4de-456c-fff2-c272ad641ed8"
      },
      "source": [
        "loaded_model_6 = tf.keras.models.load_model('model_6.h5',\n",
        "                                            custom_objects = {\"KerasLayers\": hub.KerasLayer})"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-f171309de928>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m loaded_model_6 = tf.keras.models.load_model('model_6.h5',\n\u001b[0;32m----> 2\u001b[0;31m                                             custom_objects = {\"KerasLayers\": hub.KerasLayer})\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m   raise IOError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, compile, options)\u001b[0m\n\u001b[1;32m    119\u001b[0m   \u001b[0;31m# Look for metadata file or parse the SavedModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m   \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_metadata_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSavedMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m   \u001b[0mmeta_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_graphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m   \u001b[0mobject_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_graph_def\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0mpath_to_metadata_pb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_METADATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;34m\"SavedModel file does not exist at: %s%s{%s|%s}\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         (export_dir, os.path.sep, constants.SAVED_MODEL_FILENAME_PBTXT,\n\u001b[0;32m--> 116\u001b[0;31m          constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: model_6.h5/{saved_model.pbtxt|saved_model.pb}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgMJ9dd0N86P"
      },
      "source": [
        "# Now let's save to the `SavedModel` format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vLDxScmORoH"
      },
      "source": [
        "model_6.save(\"model_6_SavedModel_format\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxpWgmfaOfHy"
      },
      "source": [
        "loaded_model_6_SavedModel_format = tf.keras.models.load_model(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sHJSUEAO-wa"
      },
      "source": [
        "## Finding the most wrong examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Un6OhPq8QACC",
        "outputId": "51ac14c7-3515-44ba-bce2-a99b7db56b5e"
      },
      "source": [
        "# Download a dataframe from google storage\n",
        "\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip\n",
        "!unzip 08_model_6_USE_feature_extractor.zip"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-26 20:02:06--  https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 74.125.199.128, 74.125.142.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 960779165 (916M) [application/zip]\n",
            "Saving to: ‘08_model_6_USE_feature_extractor.zip’\n",
            "\n",
            "08_model_6_USE_feat 100%[===================>] 916.27M   244MB/s    in 3.8s    \n",
            "\n",
            "2021-05-26 20:02:10 (239 MB/s) - ‘08_model_6_USE_feature_extractor.zip’ saved [960779165/960779165]\n",
            "\n",
            "Archive:  08_model_6_USE_feature_extractor.zip\n",
            "   creating: 08_model_6_USE_feature_extractor/\n",
            "   creating: 08_model_6_USE_feature_extractor/assets/\n",
            "   creating: 08_model_6_USE_feature_extractor/variables/\n",
            "  inflating: 08_model_6_USE_feature_extractor/variables/variables.data-00000-of-00001  \n",
            "  inflating: 08_model_6_USE_feature_extractor/variables/variables.index  \n",
            "  inflating: 08_model_6_USE_feature_extractor/saved_model.pb  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnBrkxt2PzrP"
      },
      "source": [
        "# Create a DataFrame with validation sentences and best performing model predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6odZEPp-Rf_F",
        "outputId": "3a0e4732-52c1-426f-f401-7112c9e66933"
      },
      "source": [
        "# Import previously trained model from google storage\n",
        "\n",
        "model_6_pretrained = tf.keras.models.load_model(\"08_model_6_USE_feature_extractor\")\n",
        "model_6_pretrained.evaluate(val_sentences,val_labels)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 1s 9ms/step - loss: 0.4272 - accuracy: 0.8163\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.42723122239112854, 0.8162729740142822]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ST6AFgdpRunk",
        "outputId": "e7fdec03-8838-4622-fe65-37c745ea0c9d"
      },
      "source": [
        "model_6_pretrained_pred_probs = model_6_pretrained.predict(val_sentences)\n",
        "model_6_pretrained_pred = tf.squeeze(tf.round(model_6_pretrained_pred_probs))\n",
        "model_6_pretrained_pred[:10]"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "P-di1cO0R-pT",
        "outputId": "463ced4e-bb38-4070-b256-7c2538807c98"
      },
      "source": [
        "val_df = pd.DataFrame({\"text\": val_sentences,\n",
        "                       \"target\": val_labels,\n",
        "                       \"pred\": model_6_pretrained_pred,\n",
        "                       \"pred_prob\": tf.squeeze(model_6_pretrained_pred_probs)})\n",
        "val_df.head()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.159757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.747162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gunmen kill four in El Salvador bus attack: Su...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.988749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@camilacabello97 Internally and externally scr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.196229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Radiation emergency #preparedness starts with ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.707808</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  target  pred  pred_prob\n",
              "0  DFR EP016 Monthly Meltdown - On Dnbheaven 2015...       0   0.0   0.159757\n",
              "1  FedEx no longer to transport bioterror germs i...       0   1.0   0.747162\n",
              "2  Gunmen kill four in El Salvador bus attack: Su...       1   1.0   0.988749\n",
              "3  @camilacabello97 Internally and externally scr...       1   0.0   0.196229\n",
              "4  Radiation emergency #preparedness starts with ...       1   1.0   0.707808"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "nzGJTfvYSf5X",
        "outputId": "0bd32c3f-2665-416c-fd11-51af5a7d5d0c"
      },
      "source": [
        "# find the wrong predictions and sort by prediction probabilities\n",
        "\n",
        "most_wrong = val_df[val_df['target'] != val_df['pred']].sort_values(\"pred_prob\", ascending = False)\n",
        "most_wrong.head() # false positives"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.910196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>759</th>\n",
              "      <td>FedEx will no longer transport bioterror patho...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.876982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>628</th>\n",
              "      <td>@noah_anyname That's where the concentration c...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.852300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>Ashes 2015: AustraliaÛªs collapse at Trent Br...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.835454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>@AshGhebranious civil rights continued in the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.827213</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  target  pred  pred_prob\n",
              "31   ? High Skies - Burning Buildings ? http://t.co...       0   1.0   0.910196\n",
              "759  FedEx will no longer transport bioterror patho...       0   1.0   0.876982\n",
              "628  @noah_anyname That's where the concentration c...       0   1.0   0.852300\n",
              "209  Ashes 2015: AustraliaÛªs collapse at Trent Br...       0   1.0   0.835454\n",
              "251  @AshGhebranious civil rights continued in the ...       0   1.0   0.827213"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "0TRpOn-bTKVh",
        "outputId": "abbec8cd-4c2f-4e3a-d5f7-6a9fc0e22dcb"
      },
      "source": [
        "most_wrong.tail() # false negatives"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>411</th>\n",
              "      <td>@SoonerMagic_ I mean I'm a fan but I don't nee...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.043918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>I get to smoke my shit in peace</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.042087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Why are you deluged with low self-image? Take ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>Reddit Will Now QuarantineÛ_ http://t.co/pkUA...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Ron &amp;amp; Fez - Dave's High School Crush https...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.037186</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  target  pred  pred_prob\n",
              "411  @SoonerMagic_ I mean I'm a fan but I don't nee...       1   0.0   0.043918\n",
              "233                    I get to smoke my shit in peace       1   0.0   0.042087\n",
              "38   Why are you deluged with low self-image? Take ...       1   0.0   0.038998\n",
              "244  Reddit Will Now QuarantineÛ_ http://t.co/pkUA...       1   0.0   0.038949\n",
              "23   Ron &amp; Fez - Dave's High School Crush https...       1   0.0   0.037186"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7_K_EhnTdTn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}